# Image Search Engine for ABC Grocery [Convolutional Neural Network (CNN)]

## Project Overview:
The **ABC Grocery Image Search Engine** project utilizes a **Convolutional Neural Network (CNN)**, specifically a pre-trained **VGG16 model**, to create an image search system for ABC Grocery’s product catalogue. The goal is to find similar products based on a given query image, allowing for efficient product discovery and recommendation. By leveraging **transfer learning**, the VGG16 model extracts high-level feature vectors that represent the content of product images, enabling the system to compare and retrieve similar products.

## Objective:
The primary goal of this project is to build an **image retrieval system** that helps ABC Grocery customers find similar products based on an image input. This system enhances the shopping experience by allowing customers to visually search for products similar to those they are interested in, improving customer engagement and satisfaction.

## Key Features:
- **Feature Extraction with Pre-trained CNN**: The project leverages **VGG16**, a popular CNN model pre-trained on a large image dataset (ImageNet), as a feature extractor. By excluding the top layers of VGG16 and using its convolutional layers, we extract 512-dimensional feature vectors from each product image in ABC Grocery’s catalog.
- **Image Preprocessing**: 
  - **Resizing**: Product images are resized to a consistent dimension of **224x224 pixels**, which is required by the VGG16 model.
  - **Normalization**: Pixel values are scaled to the range [0, 1] by dividing them by 255, ensuring uniform input for the CNN.
  - **Data Augmentation**: Minor image transformations (such as random rotations and flips) are applied to improve the robustness of the feature extraction process and to simulate diverse customer-uploaded images.

- **Similarity Search**: Using the extracted feature vectors, the project implements a **nearest neighbor** search mechanism to identify the most similar products to a given query image. The **cosine distance metric** is employed to measure the similarity between feature vectors, ensuring an efficient and accurate comparison.

## Methods & Techniques:

### **1. Pre-trained Model (VGG16)**:
   - The VGG16 model, known for its deep architecture and excellent performance in image classification tasks, is used as a feature extractor. The model is loaded without the top fully connected layers, allowing us to access the feature maps generated by the convolutional layers.
   - **Transfer Learning** is applied by using the pre-trained weights of VGG16 and fine-tuning the model to extract features specific to ABC Grocery's product catalog.

### **2. Image Preprocessing**:
   - **Resizing**: Product images are resized to a consistent dimension of **224x224 pixels**, which is required by the VGG16 model.
   - **Normalization**: Pixel values are scaled to the range [0, 1] by dividing them by 255, ensuring uniform input for the CNN.
   - **Data Augmentation**: Minor image transformations (such as random rotations and flips) are applied during training to increase the robustness of the feature extraction process.

### **3. Feature Extraction**:
   - Using the VGG16 model, we extract 512-dimensional feature vectors for each product image in ABC Grocery’s catalog. These vectors capture the content and characteristics of the products, such as shape, texture, and color.

### **4. Image Search with Nearest Neighbors**:
   - **Nearest Neighbors**: After extracting feature vectors from the product images, the search engine performs similarity search using the **k-Nearest Neighbors** (k-NN) algorithm. Given a query image, its feature vector is compared against those of all other product images in the catalog.
   - **Cosine Similarity**: The cosine similarity metric is used to calculate the distance between the query image’s feature vector and the feature vectors of the other product images. The smaller the distance, the more similar the images are.

### **5. Visualization of Results**:
   - The system visualizes the search results by displaying the most similar product images alongside their similarity scores (cosine distance), providing the user with relevant and accurate product recommendations.

## Technologies Used:
- **Python**: Programming language for implementing the entire image search engine.
- **TensorFlow/Keras**: For implementing the **VGG16** model, performing feature extraction, and utilizing CNN layers for feature extraction.
- **NumPy**: For handling arrays and mathematical operations during the feature extraction and comparison process.
- **scikit-learn**: Implements the **Nearest Neighbors** algorithm and the cosine similarity metric for efficient image search.
- **matplotlib**: Used for visualizing the search results and displaying images and similarity scores in a user-friendly format.
- **pickle**: Used for saving and loading the feature vectors and pre-trained models, allowing for easy deployment and reuse.

## Key Results & Outcomes:
- The **Image Search Engine** successfully identifies and ranks similar products based on the input image. By utilizing the **VGG16 CNN model**, the system captures intricate visual features and enables high-accuracy image retrieval.
- The system's performance is validated by testing the similarity search functionality, ensuring that products with similar content are returned first.
- **Cosine similarity** ensures the efficiency of the search, producing relevant and reliable results based on the similarity between feature vectors.

## Lessons Learned:
- **Transfer Learning** with pre-trained models like **VGG16** is highly effective for tasks such as image feature extraction, significantly reducing the need for training a model from scratch.
- **Feature representation** through CNNs captures intricate details that are vital for performing accurate image similarity searches.
- **Nearest Neighbors** is a simple yet powerful technique for searching through high-dimensional spaces, providing a scalable solution for content-based image retrieval.

## Future Enhancements:
- **Model Fine-tuning**: Fine-tuning the VGG16 model by adding custom layers on top of the pre-trained network could improve the accuracy of feature extraction specific to ABC Grocery's product images.
- **Efficient Search Algorithms**: Implementing more efficient algorithms like **Approximate Nearest Neighbors** (ANN) could further improve search speed, especially for large product catalogs.

